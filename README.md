# Local_ai_agent
Run llm locally using Ollama, Langchain and Rag
